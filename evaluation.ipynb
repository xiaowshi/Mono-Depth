{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOzMCKqZVuqUt+RLFlpe5nS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ItsShi/Mono-Depth/blob/main/evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGj4DakSsUmj",
        "outputId": "ea973250-5cd4-48b6-b9a2-7d6d51f9b1c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MonoDepth'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Counting objects: 100% (162/162), done.\u001b[K\n",
            "remote: Compressing objects: 100% (128/128), done.\u001b[K\n",
            "remote: Total 166 (delta 66), reused 83 (delta 27), pack-reused 4\u001b[K\n",
            "Receiving objects: 100% (166/166), 10.44 MiB | 30.44 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ItsShi/MonoDepth.git\n",
        "\n",
        "!pip -q install tensorboardX==1.4\n",
        "!pip -q install torchvision==0.12.0\n",
        "!pip -q install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "video_url = 'https://drive.google.com/uc?id=1c_ewx6wts7pJTb3XVWVXEZLbFXDObpdP'\n",
        "gdown.download(video_url,'SCARED_video.zip',quiet=True) \n",
        "\n",
        "!unzip -q /content/SCARED_video.zip"
      ],
      "metadata": {
        "id": "pQW2jxWsv61U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# depth gt\n",
        "!pwd\n",
        "import gdown\n",
        "import shutil\n",
        "\n",
        "scene_url = 'https://drive.google.com/uc?id=1xZwB0qFWbU7EjjI1g-Y0pqAs1_nWwU6Z'\n",
        "gdown.download(scene_url, 'scene.tar.gz', quiet=True)\n",
        "\n",
        "shutil.unpack_archive('scene.tar.gz', 'd3k1_tiffs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxfRys6Bsnrb",
        "outputId": "c05070c9-7def-4c92-9d50-5f18b6dbce89"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vid2frame\n",
        "!pip install ffmpeg\n",
        "!mkdir /content/data\n",
        "!ffmpeg -i /content/d3k1_rgb.mp4 %6d.jpg  \n",
        "!mv *.jpg /content/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TfwO3ResZ7B",
        "outputId": "38ab05f9-cc01-4438-8e9d-54cc7213ec23"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=136c80e9897a007a02462acb7df75951324f09704edf54693bfb4922b0632dd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/d3k1_rgb.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf56.40.101\n",
            "  Duration: 00:00:13.16, start: 0.000000, bitrate: 31151 kb/s\n",
            "    Stream #0:0(und): Video: h264 (High 4:4:4 Predictive) (avc1 / 0x31637661), yuv444p, 1280x2048, 31148 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;34m[swscaler @ 0x558d20d14c40] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
            "\u001b[0mOutput #0, image2, to '%6d.jpg':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf58.29.100\n",
            "    Stream #0:0(und): Video: mjpeg, yuvj444p(pc), 1280x2048, q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      encoder         : Lavc58.54.100 mjpeg\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
            "frame=  329 fps= 15 q=24.8 Lsize=N/A time=00:00:13.16 bitrate=N/A speed=0.58x    \n",
            "video:39020kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_files\n",
        "!touch train_files.txt\n",
        "!touch val_files.txt\n",
        "!touch test_files.txt\n",
        "\n",
        "for opt in [\"train\", \"val\", \"test\"]:\n",
        "    f = open(\"/content/MonoDepth/splits/endovis/{}_files.txt\".format(opt), \"r+\")\n",
        "    new_file = []\n",
        "    for line in f:\n",
        "      folder, frame = line.split()[0], line.split()[1]\n",
        "      if folder == \"dataset3/keyframe4\" and int(frame)<328:\n",
        "          new_file.append(line)\n",
        "    print(len(new_file))\n",
        "    with open(\"{}_files.txt\".format(opt), \"w+\") as f:\n",
        "      for i in new_file:\n",
        "        f.write(i)\n",
        "\n",
        "# move and replace the original train_files.txt file\n",
        "%pwd\n",
        "!cp /content/MonoDepth/splits/endovis/test_files.txt /content/test_files_original.txt\n",
        "!cp -f /content/val_files.txt /content/MonoDepth/splits/endovis/val_files.txt\n",
        "!cp -f /content/train_files.txt /content/MonoDepth/splits/endovis/train_files.txt\n",
        "!cp -f /content/test_files.txt /content/MonoDepth/splits/endovis/test_files.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx0V47sEsvez",
        "outputId": "e583ad23-0eb8-4cb3-9380-000ef28e3a5f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MonoDepth\n",
        "!python export_gt_depth.py --data_path /content/d3k1_tiffs --split endovis\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIYlvbePszRK",
        "outputId": "92904e1c-9bcd-437f-f3d4-93d1be3e0401"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MonoDepth\n",
            "Exporting ground truth depths for endovis\n",
            "1\n",
            "dataset3/keyframe4\n",
            "2\n",
            "dataset3/keyframe4\n",
            "3\n",
            "dataset3/keyframe4\n",
            "4\n",
            "dataset3/keyframe4\n",
            "5\n",
            "dataset3/keyframe4\n",
            "6\n",
            "dataset3/keyframe4\n",
            "7\n",
            "dataset3/keyframe4\n",
            "8\n",
            "dataset3/keyframe4\n",
            "9\n",
            "dataset3/keyframe4\n",
            "10\n",
            "dataset3/keyframe4\n",
            "11\n",
            "dataset3/keyframe4\n",
            "12\n",
            "dataset3/keyframe4\n",
            "13\n",
            "dataset3/keyframe4\n",
            "14\n",
            "dataset3/keyframe4\n",
            "15\n",
            "dataset3/keyframe4\n",
            "16\n",
            "dataset3/keyframe4\n",
            "17\n",
            "dataset3/keyframe4\n",
            "18\n",
            "dataset3/keyframe4\n",
            "19\n",
            "dataset3/keyframe4\n",
            "20\n",
            "dataset3/keyframe4\n",
            "21\n",
            "dataset3/keyframe4\n",
            "22\n",
            "dataset3/keyframe4\n",
            "23\n",
            "dataset3/keyframe4\n",
            "24\n",
            "dataset3/keyframe4\n",
            "25\n",
            "dataset3/keyframe4\n",
            "26\n",
            "dataset3/keyframe4\n",
            "27\n",
            "dataset3/keyframe4\n",
            "28\n",
            "dataset3/keyframe4\n",
            "29\n",
            "dataset3/keyframe4\n",
            "30\n",
            "dataset3/keyframe4\n",
            "31\n",
            "dataset3/keyframe4\n",
            "32\n",
            "dataset3/keyframe4\n",
            "33\n",
            "dataset3/keyframe4\n",
            "34\n",
            "dataset3/keyframe4\n",
            "Saving to endovis\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MonoDepth\n",
        "!python evaluate_depth.py --dpt --eval_split endovis --data_path /content/data --eval_mono  --width 320 --height 256 \n",
        "# --load_weights_folder \n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXjigGU6s6R6",
        "outputId": "bdc7fbe9-3ae3-4f74-8eef-2e75220c09be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MonoDepth\n",
            "2023-06-09 15:27:17.419392: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Downloading (…)rocessor_config.json: 100% 285/285 [00:00<00:00, 1.79MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/dpt/feature_extraction_dpt.py:28: FutureWarning: The class DPTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use DPTImageProcessor instead.\n",
            "  warnings.warn(\n",
            "Downloading (…)lve/main/config.json: 100% 942/942 [00:00<00:00, 6.51MB/s]\n",
            "Downloading pytorch_model.bin: 100% 1.37G/1.37G [00:21<00:00, 64.4MB/s]\n",
            "Some weights of DPTForDepthEstimation were not initialized from the model checkpoint at Intel/dpt-large and are newly initialized: ['neck.fusion_stage.layers.0.residual_layer1.convolution2.weight', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution1.weight', 'neck.fusion_stage.layers.0.residual_layer1.convolution1.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/MonoDepth/evaluate_depth.py\", line 272, in <module>\n",
            "    evaluate(options.parse())\n",
            "  File \"/content/MonoDepth/evaluate_depth.py\", line 143, in evaluate\n",
            "    output = depth_decoder(**encoding)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/dpt/modeling_dpt.py\", line 1123, in forward\n",
            "    outputs = self.dpt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/dpt/modeling_dpt.py\", line 925, in forward\n",
            "    embedding_output = self.embeddings(pixel_values, return_dict=return_dict)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/dpt/modeling_dpt.py\", line 250, in forward\n",
            "    batch_size, num_channels, height, width = pixel_values.shape\n",
            "AttributeError: 'list' object has no attribute 'shape'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5V4LJR6qwWZK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}